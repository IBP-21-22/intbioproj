{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wheel\n",
    "# !pip install h5py\n",
    "# !pip install torch==1.10.0+cu113 torchvision==0.11.1+cu113 torchaudio==0.10.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import h5py\n",
    "import yaml\n",
    "import pickle\n",
    "import os\n",
    "import argparse\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "from dataclasses import dataclass, field\n",
    "import contextlib\n",
    "import math\n",
    "from heapq import merge\n",
    "from math import floor\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import product\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import spearmanr, pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../processed_data/utrs.csv')\n",
    "data = data[['Gene Name', 'foreign']].dropna(axis=0).rename(columns={'Gene Name': 'gene', 'foreign':'seq'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VPS8</td>\n",
       "      <td>ACATTTCTAAATATTTAATACAACTTTGGTTACATAAAAGTAAAAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SSA1</td>\n",
       "      <td>AGCCAATTGGTGCGGCAATTGATAATAACGAAAATGTCTTTTAATG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ERP2</td>\n",
       "      <td>AGAACTTTTCAATCTACGAAAAATATATGTCCGCAATATAGAACAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FUN14</td>\n",
       "      <td>AGCAAGACAAATGACCAGATATAAACGAGGGTTATATTCTTTCGTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SPO7</td>\n",
       "      <td>AAAGAGTTGGAGGGCTTCTTCCTTCGAATAAGAGGTCATATTTACC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gene                                                seq\n",
       "4   VPS8  ACATTTCTAAATATTTAATACAACTTTGGTTACATAAAAGTAAAAT...\n",
       "5   SSA1  AGCCAATTGGTGCGGCAATTGATAATAACGAAAATGTCTTTTAATG...\n",
       "6   ERP2  AGAACTTTTCAATCTACGAAAAATATATGTCCGCAATATAGAACAC...\n",
       "7  FUN14  AGCAAGACAAATGACCAGATATAAACGAGGGTTATATTCTTTCGTT...\n",
       "8   SPO7  AAAGAGTTGGAGGGCTTCTTCCTTCGAATAAGAGGTCATATTTACC..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "KMER_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efficiency element\n",
    "eff_el1 = \"TATATA\"\n",
    "eff_el2 = \"TTTTTATA\"\n",
    "eff_ctrl = \"GCGCGC\"\n",
    "# Mutational scan of efficiency element?\n",
    "# Positioning element\n",
    "pos_el = \"AAWAAA\"\n",
    "# Puf protein binding sites\n",
    "puf1_2 = \"TAATNNNTAAT\"\n",
    "puf3 = \"TGTANATA\"\n",
    "puf4 = \"TGTANANTA\"\n",
    "puf5 = \"TGTANNNNTA\"\n",
    "puf6 = \"TTGT\"\n",
    "# Poly-T sequences\n",
    "poly_t = \"TTTTTTTT\"\n",
    "_elems = [eff_el1, eff_el2, eff_ctrl,\n",
    "           pos_el,\n",
    "           puf1_2, puf3, puf4, puf5, puf6,\n",
    "           poly_t]\n",
    "specElements = []\n",
    "# expand elements above by replacing Ns with A,T,G or C and Ws with A or T\n",
    "for elem in _elems:\n",
    "    specElements.extend([''.join(y) for y in list(product(*(['A', 'T', 'G', 'C'] if x=='N'  else (\n",
    "        ['A', 'T'] if x=='W' else  (x,)) for x in elem)))])\n",
    "# augment elements using all contiguous subsequences of size k - 1  of them, if the element size is larger than K\n",
    "specElements = list(set(specElements + sum([[x[:-1], x[1:]] for x in specElements if len(x) > KMER_SIZE], [])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.seq.apply(lambda x: len(x)>=KMER_SIZE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1037"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(specElements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Stride (overlap) of subsequence reading based on current subsequence entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(string):\n",
    "    \"Calculates the Shannon entropy of a string\"\n",
    "\n",
    "    # get probability of chars in string\n",
    "    prob = [ float(string.count(c)) / len(string) for c in dict.fromkeys(list(string)) ]\n",
    "\n",
    "    # calculate the entropy\n",
    "    entropy = - sum([ p * math.log(p) / math.log(2.0) for p in prob ])\n",
    "\n",
    "    return min(1, abs(entropy) / 2)\n",
    "def compute_stride(seq):\n",
    "    return max(1, round(len(seq) * (1 - entropy(seq))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply stride computation to the 20 first specific elements above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AATATATAAT', 5),\n",
       " ('TAATGACTAAT', 2),\n",
       " ('TGTATGACTA', 1),\n",
       " ('TAATTGGTAAT', 3),\n",
       " ('GTATAAGTA', 2),\n",
       " ('TGTAGTATT', 3),\n",
       " ('TGTAACTGTA', 1),\n",
       " ('TGTATCGTTA', 1),\n",
       " ('TAATCTCTAA', 2),\n",
       " ('TGTAGGATTA', 2),\n",
       " ('GTAAATA', 2),\n",
       " ('TGTAAAATT', 3),\n",
       " ('GTAATTGTA', 2),\n",
       " ('GTAACAATA', 2),\n",
       " ('GTATGCCTA', 1),\n",
       " ('TGTATCCTT', 2),\n",
       " ('GTACTTATA', 1),\n",
       " ('TGTACGGCT', 1),\n",
       " ('TAATGATTAAT', 4),\n",
       " ('GTACGCCTA', 1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_strides = [compute_stride(s) for s in specElements[:20]]\n",
    "list(map(tuple, zip(*[specElements,search_strides])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_kmer_adaptive(seq, sub, stride):\n",
    "    # Search positions of subsequence in seq, while respecting provided stride, in case of a hit\n",
    "    found = []\n",
    "    pos = 0\n",
    "    while pos < len(seq):\n",
    "        if seq[pos:pos+len(sub)] == sub:\n",
    "            found.append(pos)\n",
    "            pos += stride\n",
    "        else:\n",
    "            pos += 1\n",
    "    return found\n",
    "\n",
    "def get_kmers_adaptive(seq, k, min_stride):\n",
    "    #Get K-Mers existing in the sequence seq, while computing the stride based on entropy and \n",
    "    #respecting a minimum stride\n",
    "    kmers = []\n",
    "    pos = 0\n",
    "    while pos < len(seq):\n",
    "        if pos + k > len(seq):\n",
    "            break\n",
    "        kmers.append(seq[pos:pos+k])\n",
    "        pos += max(min_stride, compute_stride(kmers[-1]))\n",
    "    return kmers\n",
    "\n",
    "def search_all_kmers(seq, specElements, kmer_size, min_stride=1):\n",
    "    # sort specific elements based on their length, so in case of overlap hit,\n",
    "    # found sequences are ordered in a logical matter\n",
    "    # eg AGT and AGTAC found both in position j, the produced string will be \"AGT AGTAC\"\n",
    "    specElements = sorted(specElements, key=len)\n",
    "    pairs = []\n",
    "    # Retrieve the found positions of each element and merge all the found elements positions together\n",
    "    for elem in specElements:\n",
    "        pos = search_kmer_adaptive(seq, elem, compute_stride(elem))\n",
    "        new_words_len = [len(elem) for _ in range(len(pos))]\n",
    "        new_words = [elem for _ in range(len(pos))]\n",
    "        new_pairs = list(map(tuple, zip(*[pos,new_words_len,new_words]))) \n",
    "        pairs = merge(pairs, new_pairs)\n",
    "    pairs = [(x[0],x[0] + x[1], x[2]) for x in list(pairs)]\n",
    "    # For the remaining intervals, in between found elements, get the kmers of the specific kmer_size\n",
    "    # and with the minimum stride min_stride\n",
    "    final_sequence = []\n",
    "    # start of sequence (before findings)\n",
    "    if not pairs:\n",
    "        return get_kmers_adaptive(seq, kmer_size, min_stride)\n",
    "    final_sequence =  get_kmers_adaptive(seq[:pairs[0][0] + compute_stride(pairs[0][2])], kmer_size, min_stride)\n",
    "    # middle of sequence (with intertwined findings)\n",
    "    for cnt in range(len(pairs) - 1):\n",
    "        final_sequence.append(pairs[cnt][2])\n",
    "        final_sequence.extend(\n",
    "            get_kmers_adaptive(\n",
    "                seq[pairs[cnt][1] - compute_stride(pairs[cnt][2]) :\n",
    "                    pairs[cnt+1][0] + compute_stride(pairs[cnt + 1][2])], kmer_size, min_stride))\n",
    "    # end of sequence (after findings)\n",
    "    final_sequence.append(pairs[-1][2])\n",
    "    final_sequence.extend(\n",
    "        get_kmers_adaptive(seq[pairs[-1][1] - compute_stride(pairs[-1][2]):],\n",
    "                           kmer_size, min_stride))\n",
    "    return final_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example of how the first 3'UTR sequence is split based on the algorithm above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACATTTCTAAATATTTAATACAACTTTGGTTACATAAAAGTAAAATTTATACACCTCATTTCATTATGTAGATTCATATATAGAATACCAATTATGATTG'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.seq.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACATT',\n",
       " 'CATTT',\n",
       " 'TTTCT',\n",
       " 'CTAAA',\n",
       " 'AAATA',\n",
       " 'AATATTTAAT',\n",
       " 'TTAAT',\n",
       " 'ATACA',\n",
       " 'ACAAC',\n",
       " 'ACTTT',\n",
       " 'TTTGG',\n",
       " 'GGTTA',\n",
       " 'GTTAC',\n",
       " 'TTACA',\n",
       " 'TACAT',\n",
       " 'ACATA',\n",
       " 'ATAAA',\n",
       " 'AAAAG',\n",
       " 'AGTAA',\n",
       " 'TAAAA',\n",
       " 'AATTT',\n",
       " 'TTATA',\n",
       " 'TACAC',\n",
       " 'ACACC',\n",
       " 'CCTCA',\n",
       " 'TCATT',\n",
       " 'ATTTC',\n",
       " 'TTCAT',\n",
       " 'CATTA',\n",
       " 'ATTAT',\n",
       " 'TGTAGAT',\n",
       " 'TGTAGATT',\n",
       " 'TTCAT',\n",
       " 'ATATA',\n",
       " 'TATAT',\n",
       " 'TATATA',\n",
       " 'ATAGA',\n",
       " 'AGAAT',\n",
       " 'AATAC',\n",
       " 'TACCA',\n",
       " 'ACCAA',\n",
       " 'AATTA',\n",
       " 'TATGA',\n",
       " 'ATGAT',\n",
       " 'TGATT']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_all_kmers(data.seq.iloc[0], specElements, KMER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864807bbacae4346ba30ab22882ee676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "preprocessed_seq = data.seq.progress_apply(search_all_kmers, specElements=specElements, kmer_size=KMER_SIZE)\n",
    "corpus = [y  for x in preprocessed_seq for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACATT CATTT TTTCT CTAAA AAATA AATATTTAAT TTAAT ATACA ACAAC ACTTT TTTGG GGTTA GTTAC TTACA TACAT ACATA ATAAA AAAAG AGTAA TAAAA AATTT TTATA TACAC ACACC CCTCA TCATT ATTTC TTCAT CATTA ATTAT TGTAGAT TGTAGATT TTCAT ATATA TATAT TATATA ATAGA AGAAT AATAC TACCA ACCAA AATTA TATGA ATGAT TGATT\r\n",
      "AGCCA GCCAA CCAAT CAATT AATTG ATTGG TTGGT GTGCG GCGGC GCAAT AATTGATAAT AATAA TAACG AACGA CGAAA AAAAT ATGTC TGTCT TCTTT TTTAA AATGA TGATC GATCT ATCTG TCTGG CTGGG GGGTA GTATA TATAA AATGA TGAGG AGGAA AATTT TTTCC CCGAA CGAAC GAACG AACGT ACGTT CGTTT TTTTT ACTTT TTTAT TATAT TATATA ATATA TATAT TATATA ATATA TATAT TATATA ATATA ATACA ACATG CATGT ATGTA TGTAA GTAAC TAACA ACATA ATATA TATAT TATTC TTCTA CTATA TATAC ATACG TACGC ACGCT CGCTA GCTAT CTATA TATAG ATAGA AGAGA GAAAG AGGAA AAATT TTTTT CAATT\r\n",
      "AGAAC AACTT ACTTT TTTTC TCAAT CAATC AATCT ATCTA TCTAC CTACG TACGA ACGAA GAAAA AAAAA AAAAA ATATA TATAT TATGT TGTCC GTCCG TCCGC CGCAA GCAAT CAATA ATATA ATAGA AGAAC AACAC ACAAT AATTA TAGGT AGGTT GGTTT TATAT TATTC TTCGA TCGAC CGACG GACGT ACGTG CGTGA GTGAT TGATT ATTTT TTTTT TTTTTTT TTTTT TTTTTTTT TTTTT TTTTC TCTTC TCCTT TTAGC TAGCC AGCCC CCCTA CTATG TGTATAT TGTATATT TGTATATTT TGTATATTTA GTATATTTA TATAT TATTT TTACT ACTGT CTGTA TGTAT TATAG ATAGG TAGGA AGGAT GGATA ATAAA AAATG ATGAA GAAAT AATAC TACCA ACCAA AAAAA AAAAA AAAAA AATAA AATAAA ATAAA AAAAA AAAAA AAAAA AAAAAA AAAAA AGTAT GTATA ATAAA AAAAC ACGAA GAAAG AGAAT ATATA ATAAC AACCC CCTCG TCGTT GTTTA TATAT TATCT TCTGG CTGGT TGGTC GGTCA GTCAT TCATT TTGT GTCTT CTTGC TTGCT GCTCA CTCAT TCATT TTGT GTTAG TTAGC TAGCA AGCAT GCATT CATTT TTTAA AAACT ACTTG CTTGC TTGCT GCTAA CTAAT TAATA TACGA ACGAA GAAAC AACTC ACTCA CTCAA TCAAT CAATG AATGT ATGTA TGTAA GTAAA AAAGA GAATA ATACT TACTT CTTTA TTAAA AAACC CCCAT CATGT ATGTA TGTAT TATTC TTCTG CTGTA TGTAC GTACC TACCC CCCAA AATAA TAACC AACCC CCATC ATCAA AATAA TAAGC AAGCA GCAGT CAGTT\r\n",
      "AGCAA CAAGA AGACA ACAAA AATGA TGACC GACCA ACCAG CCAGA CAGAT AGATA ATATA ATAAA AAACG ACGAG CGAGG AGGGT GGTTA GTTAT TATAT TATTC TTCTT TTTCG TCGTT GTTTT TTTTATA TATAC ATACT TACTT CTTTT TTTTTAT TTTAT ATTTT TTTGG GGTAT GTATT ATTTC TTCAT CATTT TTTAT ATCCT TCCTA CCTAT CTATA TATAC ATACA ACAGT GTAAATA GTAAATATA ATATA ATACA ACATA ATAGG TAGGG GGGCT GCTAA CTAAG TAAGG AAGGA GAAGA GAAAA AAAAA AAAAA AAAAAA AAAAA AAAAT ATCAC TCACG CACGT ACGTC CGTCG\r\n",
      "AAAGA GAGTT AGTTG GTTGG GGAGG GGGCT GCTTC CTTCT CTTCC CCTTC TCGAA CGAAT AATAA TAAGA AGAGG GGTCA GTCAT TCATA CATAT ATATT TTTAC TACCT ACCTA CCTAT CTATG TGTAAAAT TGTAAAATT TTGT TGTAACCAT TCTAT TATGT TGTTC TTCAC TCACA CACAC ACATA ATAAA AAATT TATAT TATTT TTTTATA TATAC ATACA ACATT CATTA ATTAT ATTAG TTAGA TAGAA GAAGT AAGTG AGTGA GTGAA TGAAG GAAGC AAGCT AGCTG GCTGT CTGTT TTGT GTGTC TGTCG GTCGT TCGTG CGTGA GTGAA TGAAA AAAAT ATTTT\r\n",
      "ATGAG TGAGT GAGTA AGTAA TAATG AATGT ATGTG TGTGA GTGAA TGAAA AATAA AATAAA ATAAA AAAAT AATAA AATAAA ATAAA AAAGG GGTTT TTTAA ATATA ATACA ACAGG CAGGT AGGTT GGTTA GTTAA TTAAA AAAAA AAAAA AAAAAA AAAAA AATAA AATAAGTAAT TAATA TACAA CAATG AATGT ATGTG TGTATAAT ATCAT TCATA CATAA TAATG AATGG ATGGC TGGCG GCGTT CGTTA GTTAA TTAAA AAGCA GCAGA CAGAA AATAA AATAAA ATAAA AAAGT AGTAA TAACC AACCG ACCGA CCGAA CGAAC GAACA ACACC CCTTA CTTAT TATCT TCTTT TTGT GTGTC TGTCT TCTTC TCTGC CTGCT TGCTT CTTCT CTCAT TCATG CATGG ATGGC TGGCG GCGTG GTGCT TGCTC GCTCC TCCCA CCACT ACTCA CTCAT TCATT ATTTA TAGTT GTTCG TTCGA TCGAA CGAAC GAACC AACCG ACCGC CGCAA GCAAA AAACT ACTTT TTTCG TCGCT CGCTC CTCAA TCAAA AAAGC\r\n",
      "AGGTG GTGTT TTCGG TCGGT CGGTT GGTTA GTTAC TTACT ACTTT TTTAT ATTCT TCTGC CTGCT TGCTT CTTTA TTAAC TAACG AACGC ACGCC GCCAT CCATT CATTA ATTAT ATGAT TGATT ATTAT ATACA ACACA TTGT TGTATTACT CTTAT TATTT TTTTT AACCT ACCTG TGTATAT TGTATATT TGTATATTA GTATATTA TATAT TATTA TAAAA AACCT ACCTT CCTTT TTATT TTTTA TATTT TTCAC TCACA CACAT ACATT CATTA ATTAC TTACT ACTCA CTCAT TCATC CATCA ATCAT TCATG CATGT ATGTG TGTGG GGAGT AGTAC GTACT TACTG ACTGG CTGGA TGGAA GGAAT GAATT TTGT GTATG TATGC ATGCC\r\n",
      "ATCGC TCGCC GCCAG CCAGT CAGTG AGTGC GTGCC TGCCA GCCAC CACGT ACGTC CGTCT GTCTC TCTCT CTGCC GCCTT CCTTC TCGAC CGACC ACCGG CCGGA CGGAC GGACC GACCT ACCTT CCTTT TTTTA TAAGT AAGTA GTACG TACGA ACGAT CGATA ATAAA AAATA TATCC ATCCT TCCTT TTTTATA ATAAA AAATA ATATA TATAT TATATA ATAGT TAGTC AGTCT GTCTA TCTAA CTAAA AAAAT ATATC TATCC ATCCA TCCAT CCATT CATTA ATTAA AATAC TACTG ACTGT CTGTG TGTGC GTGCT TGCTC\r\n",
      "ACCGC CGCCA CCACA CACTG ACTGG CTGGA TGGAC GGACC GACCC CCCCA CATAC ATACC TACCA ACCAC ACTTC CTTCT CTTTT TTGT GTTAT TATTC TTCTT TTAAA AATAT ATGTT TTGT TGTAACGCT TGTAACGCTA GTAACGCTA ATGTA TGTAA GTAAT TAATT TTCCA TCCAC CACCC CCTTC TCATT ATTAC TTACT ACTAA AATAA TAATT TTAGC TAGCC AGCCA GCCAT CCATT CATTC\r\n",
      "AGTGT GTGTG TGGTA GGTAA GTAAA AAAAA AAAAA AAAAA AAAAAA AAAAA AAAAA AAAAA AAAAA AAAAAA AAAAA AAAAA AAAAA GAAAA AAGAA AAAAG AGAAA AAGCA GCAGG AGGCC GGCCT GCCTA CCTAG CTAGT TAGTT TTGT GTTAA TTAAT TGTATACT TGTATACTT TTTTT TTTTTAT TTTAT ATTCA TTCAT CATTC ATTCA TTCAA TCAAG CAAGT TGTACAT TGTACATA TGTACATAT GTACATA ATGTG TGTGT TGTATGTAT TGTATGTAT TGTATGTATA GTATGTATA TGTATAT TGTATATA TGTATATAT GTATATA TATAT TATATA ATATA ATATT TTTGA TGAAC GAACT AACTA CTAGT TAGTA AGTAT GTATC TATCA ATCAA CAATT AATTT TTTTT AAAAG AGTTC GTTCT TCTTG TTGAC TGACA GACAT ACATT CATTC ATTCT TCTGC CTGCC\r\n"
     ]
    }
   ],
   "source": [
    "GCORPUS = f'../processed_data/utrs_corpus_{KMER_SIZE}'\n",
    "with open(GCORPUS, 'w') as out:\n",
    "    out.write('\\n'.join([' '.join(c) for c in preprocessed_seq]))\n",
    "!head ../processed_data/utrs_corpus_$KMER_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBUILD_DIR = 'glove/build'\n",
    "VERBOSE = 2\n",
    "VOCAB_FILE = f'../processed_data/.utrs_vocab_{KMER_SIZE}'\n",
    "MEMORY = 4\n",
    "WINDOW_SIZE = 10\n",
    "COOCCURRENCE_FILE = f'../processed_data/.utrs_coocc_{KMER_SIZE}_{WINDOW_SIZE}.bin'\n",
    "COOCCURRENCE_SHUF_FILE = f'../processed_data/.utrs_coocc_{KMER_SIZE}_{WINDOW_SIZE}.shuf.bin'\n",
    "SEED = 42\n",
    "VECTOR_SIZE = 50\n",
    "THREADS = 8\n",
    "ETA = 0.05\n",
    "X_MAX = 100\n",
    "MAX_ITER = 50\n",
    "SAVE_FILE = f'../processed_data/utrs_embeddings_{KMER_SIZE}_{WINDOW_SIZE}_{VECTOR_SIZE}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUILDING VOCABULARY\r\n",
      "Processed 0 tokens.\u001b[11G100000 tokens.\u001b[11G200000 tokens.\u001b[11G300000 tokens.\u001b[11G400000 tokens.\u001b[11G500000 tokens.\u001b[11G600000 tokens.\u001b[11G700000 tokens.\u001b[0GProcessed 770208 tokens.\r\n",
      "Counted 1973 unique words.\r\n",
      "Using vocabulary of size 1973.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!$GBUILD_DIR/vocab_count -verbose $VERBOSE < $GCORPUS > $VOCAB_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COUNTING COOCCURRENCES\n",
      "window size: 10\n",
      "context: symmetric\n",
      "max product: 13752509\n",
      "overflow length: 38028356\n",
      "Reading vocab from file \"../processed_data/.utrs_vocab_5\"...loaded 1973 words.\n",
      "Building lookup table...table contains 3892730 elements.\n",
      "Processing token: 0\u001b[19G100000\u001b[19G200000\u001b[19G300000\u001b[19G400000\u001b[19G500000\u001b[19G600000\u001b[19G700000\u001b[0GProcessed 770208 tokens.\n",
      "Writing cooccurrences to disk......2 files in total.\n",
      "Merging cooccurrence files: processed 0 lines.\u001b[39G0 lines.\u001b[39G100000 lines.\u001b[39G200000 lines.\u001b[39G300000 lines.\u001b[39G400000 lines.\u001b[39G500000 lines.\u001b[39G600000 lines.\u001b[39G700000 lines.\u001b[39G800000 lines.\u001b[39G900000 lines.\u001b[39G1000000 lines.\u001b[39G1100000 lines.\u001b[39G1200000 lines.\u001b[0GMerging cooccurrence files: processed 1257757 lines.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(f\"{GBUILD_DIR}/cooccur -memory {MEMORY} -vocab-file {VOCAB_FILE} -verbose {VERBOSE} -window-size {WINDOW_SIZE} < {GCORPUS} > {COOCCURRENCE_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using random seed 42\n",
      "SHUFFLING COOCCURRENCES\n",
      "array size: 255013683\n",
      "Shuffling by chunks: processed 0 lines.\u001b[22Gprocessed 1257757 lines.\n",
      "Wrote 1 temporary file(s).\n",
      "Merging temp files: processed 0 lines.\u001b[31G1257757 lines.\u001b[0GMerging temp files: processed 1257757 lines.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f\"{GBUILD_DIR}/shuffle -memory {MEMORY} -verbose {VERBOSE} -seed {SEED} < {COOCCURRENCE_FILE} > {COOCCURRENCE_SHUF_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING MODEL\n",
      "Read 1257757 lines.\n",
      "Initializing parameters...Using random seed 1638497427\n",
      "done.\n",
      "vector size: 50\n",
      "vocab size: 1973\n",
      "x_max: 100.000000\n",
      "alpha: 0.750000\n",
      "12/03/21 - 03:10.27AM, iter: 001, cost: 0.074169\n",
      "12/03/21 - 03:10.27AM, iter: 002, cost: 0.062089\n",
      "12/03/21 - 03:10.28AM, iter: 003, cost: 0.059900\n",
      "12/03/21 - 03:10.28AM, iter: 004, cost: 0.052715\n",
      "12/03/21 - 03:10.28AM, iter: 005, cost: 0.040672\n",
      "12/03/21 - 03:10.29AM, iter: 006, cost: 0.029685\n",
      "12/03/21 - 03:10.29AM, iter: 007, cost: 0.023104\n",
      "12/03/21 - 03:10.29AM, iter: 008, cost: 0.019389\n",
      "12/03/21 - 03:10.29AM, iter: 009, cost: 0.017134\n",
      "12/03/21 - 03:10.30AM, iter: 010, cost: 0.015683\n",
      "12/03/21 - 03:10.30AM, iter: 011, cost: 0.014690\n",
      "12/03/21 - 03:10.30AM, iter: 012, cost: 0.013986\n",
      "12/03/21 - 03:10.31AM, iter: 013, cost: 0.013466\n",
      "12/03/21 - 03:10.31AM, iter: 014, cost: 0.013066\n",
      "12/03/21 - 03:10.31AM, iter: 015, cost: 0.012756\n",
      "12/03/21 - 03:10.31AM, iter: 016, cost: 0.012502\n",
      "12/03/21 - 03:10.32AM, iter: 017, cost: 0.012293\n",
      "12/03/21 - 03:10.32AM, iter: 018, cost: 0.012117\n",
      "12/03/21 - 03:10.32AM, iter: 019, cost: 0.011964\n",
      "12/03/21 - 03:10.33AM, iter: 020, cost: 0.011833\n",
      "12/03/21 - 03:10.33AM, iter: 021, cost: 0.011719\n",
      "12/03/21 - 03:10.33AM, iter: 022, cost: 0.011616\n",
      "12/03/21 - 03:10.33AM, iter: 023, cost: 0.011521\n",
      "12/03/21 - 03:10.34AM, iter: 024, cost: 0.011440\n",
      "12/03/21 - 03:10.34AM, iter: 025, cost: 0.011366\n",
      "12/03/21 - 03:10.34AM, iter: 026, cost: 0.011299\n",
      "12/03/21 - 03:10.35AM, iter: 027, cost: 0.011238\n",
      "12/03/21 - 03:10.35AM, iter: 028, cost: 0.011181\n",
      "12/03/21 - 03:10.35AM, iter: 029, cost: 0.011132\n",
      "12/03/21 - 03:10.36AM, iter: 030, cost: 0.011085\n",
      "12/03/21 - 03:10.36AM, iter: 031, cost: 0.011042\n",
      "12/03/21 - 03:10.36AM, iter: 032, cost: 0.010999\n",
      "12/03/21 - 03:10.36AM, iter: 033, cost: 0.010962\n",
      "12/03/21 - 03:10.37AM, iter: 034, cost: 0.010926\n",
      "12/03/21 - 03:10.37AM, iter: 035, cost: 0.010896\n",
      "12/03/21 - 03:10.37AM, iter: 036, cost: 0.010863\n",
      "12/03/21 - 03:10.38AM, iter: 037, cost: 0.010835\n",
      "12/03/21 - 03:10.38AM, iter: 038, cost: 0.010810\n",
      "12/03/21 - 03:10.38AM, iter: 039, cost: 0.010784\n",
      "12/03/21 - 03:10.38AM, iter: 040, cost: 0.010766\n",
      "12/03/21 - 03:10.39AM, iter: 041, cost: 0.010741\n",
      "12/03/21 - 03:10.39AM, iter: 042, cost: 0.010723\n",
      "12/03/21 - 03:10.39AM, iter: 043, cost: 0.010701\n",
      "12/03/21 - 03:10.40AM, iter: 044, cost: 0.010684\n",
      "12/03/21 - 03:10.40AM, iter: 045, cost: 0.010664\n",
      "12/03/21 - 03:10.40AM, iter: 046, cost: 0.010646\n",
      "12/03/21 - 03:10.40AM, iter: 047, cost: 0.010634\n",
      "12/03/21 - 03:10.41AM, iter: 048, cost: 0.010621\n",
      "12/03/21 - 03:10.41AM, iter: 049, cost: 0.010605\n",
      "12/03/21 - 03:10.41AM, iter: 050, cost: 0.010592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f\"{GBUILD_DIR}/glove -save-file {SAVE_FILE} -threads {THREADS} -input-file {COOCCURRENCE_SHUF_FILE} -eta {ETA} -x-max {X_MAX} -iter {MAX_ITER} -vector-size {VECTOR_SIZE} -vocab-file {VOCAB_FILE} -verbose {VERBOSE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.read_csv(SAVE_FILE + '.txt', sep=' ', index_col=0, header=None).apply(lambda x: np.array(x),axis=1).to_dict()\n",
    "embedding_keys = [x for x in mapping]\n",
    "embedding_mat = np.array([x for x in mapping.values()])\n",
    "tokenized = [[embedding_keys.index(x) for x in seq] for seq in preprocessed_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SAVE_FILE + '.pkl', 'wb') as out:\n",
    "    pickle.dump([data.gene.tolist(), tokenized, embedding_keys, embedding_mat], out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../processed_data/utrs_glove_embeddings.pkl', 'wb') as out:\n",
    "    pickle.dump({'data': [np.mean([embedding_mat[i, :] for i in t],axis=0) for t in tokenized], 'gene': data.gene.tolist()} ,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../processed_data/utrs_embeddings_5_10_50'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_FILE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intbioproj",
   "language": "python",
   "name": "intbioproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
